{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Science Project Session 5: Economics and Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    ">- [Classification: Which companies go bust?](#Classification:-Which-companies-go-bust?)\n",
    ">- [Regression: ](#Classification:-Which-companies-go-bust?)\n",
    ">- [Unsupervised learning:](#Classification:-Which-companies-go-bust?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will look at three mini projects related to Economics/Finance, applying techniques covered in Session Five and extending these a bit further. To start we will import our general data science packages here, and then add the necessary machine learning imports as we go along so that it's clear when we use what: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convergence warning disabling\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Which companies go bust?\n",
    "Data set: Taiwan bankruptcy\n",
    "- Pipeline\n",
    "- PCA\n",
    "- SMOTE\n",
    "- Metrics\n",
    "- KNN & Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read bankruptcy data set\n",
    "data  = pd.read_csv('data/bankruptcy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bankrupt   ROA(C) before interest and depreciation before interest  \\\n",
       "0         1                                           0.370594          \n",
       "1         1                                           0.464291          \n",
       "2         1                                           0.426071          \n",
       "3         1                                           0.399844          \n",
       "4         1                                           0.465022          \n",
       "\n",
       "    ROA(A) before interest and % after tax  \\\n",
       "0                                 0.424389   \n",
       "1                                 0.538214   \n",
       "2                                 0.499019   \n",
       "3                                 0.451265   \n",
       "4                                 0.538432   \n",
       "\n",
       "    ROA(B) before interest and depreciation after tax  \\\n",
       "0                                           0.405750    \n",
       "1                                           0.516730    \n",
       "2                                           0.472295    \n",
       "3                                           0.457733    \n",
       "4                                           0.522298    \n",
       "\n",
       "    Operating Gross Margin   Realized Sales Gross Margin  \\\n",
       "0                 0.601457                      0.601457   \n",
       "1                 0.610235                      0.610235   \n",
       "2                 0.601450                      0.601364   \n",
       "3                 0.583541                      0.583541   \n",
       "4                 0.598783                      0.598783   \n",
       "\n",
       "    Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
       "0                0.998969                    0.796887   \n",
       "1                0.998946                    0.797380   \n",
       "2                0.998857                    0.796403   \n",
       "3                0.998700                    0.796967   \n",
       "4                0.998973                    0.797366   \n",
       "\n",
       "    After-tax net Interest Rate   Non-industry income and expenditure/revenue  \\\n",
       "0                      0.808809                                      0.302646   \n",
       "1                      0.809301                                      0.303556   \n",
       "2                      0.808388                                      0.302035   \n",
       "3                      0.808966                                      0.303350   \n",
       "4                      0.809304                                      0.303475   \n",
       "\n",
       "   ...   Net Income to Total Assets   Total assets to GNP price  \\\n",
       "0  ...                     0.716845                    0.009219   \n",
       "1  ...                     0.795297                    0.008323   \n",
       "2  ...                     0.774670                    0.040003   \n",
       "3  ...                     0.739555                    0.003252   \n",
       "4  ...                     0.795016                    0.003878   \n",
       "\n",
       "    No-credit Interval   Gross Profit to Sales  \\\n",
       "0             0.622879                0.601453   \n",
       "1             0.623652                0.610237   \n",
       "2             0.623841                0.601449   \n",
       "3             0.622929                0.583538   \n",
       "4             0.623521                0.598782   \n",
       "\n",
       "    Net Income to Stockholder's Equity   Liability to Equity  \\\n",
       "0                             0.827890              0.290202   \n",
       "1                             0.839969              0.283846   \n",
       "2                             0.836774              0.290189   \n",
       "3                             0.834697              0.281721   \n",
       "4                             0.839973              0.278514   \n",
       "\n",
       "    Degree of Financial Leverage (DFL)  \\\n",
       "0                             0.026601   \n",
       "1                             0.264577   \n",
       "2                             0.026555   \n",
       "3                             0.026697   \n",
       "4                             0.024752   \n",
       "\n",
       "    Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
       "0                                           0.564050                   1   \n",
       "1                                           0.570175                   1   \n",
       "2                                           0.563706                   1   \n",
       "3                                           0.564663                   1   \n",
       "4                                           0.575617                   1   \n",
       "\n",
       "    Equity to Liability  \n",
       "0              0.016469  \n",
       "1              0.020794  \n",
       "2              0.016474  \n",
       "3              0.023982  \n",
       "4              0.035490  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6819 entries, 0 to 6818\n",
      "Columns: 96 entries, Bankrupt to  Equity to Liability\n",
      "dtypes: float64(93), int64(3)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Print the data set overview (dimensions, variable names, data types, null values)\n",
    "data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem that is immediately apparent is that we have a high number of features in our data. This constitutes a problem as capturing the complexities of a highly dimensional space through our model can lead us to **overfitting**. \n",
    "> This is known as the [Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality#Machine_Learning) and is definitely a topic worth exploring further.\n",
    "\n",
    "We will attempt to overcome this problem using several techniques but first, we must create our usual machine learning setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train-test split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the training vector y which has the column label 'Bankrupt'\n",
    "y = data.Bankrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare feature matrix \n",
    "X = data.drop(columns='Bankrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train-test- split using random state 253, test_size 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=253)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to cope with the high dimensionality of our data we can employ several dimensionality reduction techniques. The first one we'll explore is called **Principal Component Analysis (PCA)** and for a more in-depth treatment of the subject be sure to refer [here](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c). PCA essentially works by projecting our data points (which can be seen as vectors) into a lower dimensional space while maximizing the conserved variance of our data.\n",
    "\n",
    "To perform PCA:\n",
    "- Import the `PCA` class from the `sklearn.decomposition` module.\n",
    "- Decide on a number for `n_components`. This is going to be the new number of features.\n",
    "- Create a PCA transformer.\n",
    "- Train the transformer using the `.fit()` method.\n",
    "- Apply dimensionality reduction using the `.transform()` method.\n",
    "\n",
    "> **Note:** The `.tranfrom()` method will return a NumPy array as opposed to a pandas DataFrame.\n",
    "\n",
    "Try out reducing our training feature matrix `X_train` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PCA class\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA transformer that keeps 30 components \n",
    "pca = PCA(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.523242e+09</td>\n",
       "      <td>-1.918231e+09</td>\n",
       "      <td>-1.232079e+09</td>\n",
       "      <td>-1.776376e+09</td>\n",
       "      <td>-2.241226e+09</td>\n",
       "      <td>-2.137455e+09</td>\n",
       "      <td>-1.284218e+09</td>\n",
       "      <td>-4.522613e+08</td>\n",
       "      <td>-1.019373e+08</td>\n",
       "      <td>-5.526863e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.990670e+08</td>\n",
       "      <td>-9.863251e+05</td>\n",
       "      <td>-1.488518e+06</td>\n",
       "      <td>0.021262</td>\n",
       "      <td>-0.388106</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>-0.105008</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>0.046449</td>\n",
       "      <td>0.058511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.190167e+09</td>\n",
       "      <td>-2.229378e+09</td>\n",
       "      <td>-1.542280e+09</td>\n",
       "      <td>-1.132694e+09</td>\n",
       "      <td>-3.550784e+09</td>\n",
       "      <td>-9.206884e+08</td>\n",
       "      <td>4.735889e+09</td>\n",
       "      <td>-7.588887e+08</td>\n",
       "      <td>-1.324696e+08</td>\n",
       "      <td>-8.904601e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.230878e+06</td>\n",
       "      <td>-1.021334e+06</td>\n",
       "      <td>-1.433085e+06</td>\n",
       "      <td>-0.309381</td>\n",
       "      <td>-0.336137</td>\n",
       "      <td>-0.021758</td>\n",
       "      <td>-0.073707</td>\n",
       "      <td>-0.018794</td>\n",
       "      <td>-0.031770</td>\n",
       "      <td>0.026735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.923038e+08</td>\n",
       "      <td>-1.977646e+09</td>\n",
       "      <td>2.672523e+09</td>\n",
       "      <td>-3.915985e+09</td>\n",
       "      <td>1.047293e+09</td>\n",
       "      <td>-3.084126e+09</td>\n",
       "      <td>-3.835881e+08</td>\n",
       "      <td>-1.973793e+08</td>\n",
       "      <td>-7.613600e+07</td>\n",
       "      <td>-3.861154e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.456694e+07</td>\n",
       "      <td>-4.647027e+05</td>\n",
       "      <td>-1.496466e+06</td>\n",
       "      <td>-0.373196</td>\n",
       "      <td>0.290911</td>\n",
       "      <td>-0.039027</td>\n",
       "      <td>0.134702</td>\n",
       "      <td>0.152492</td>\n",
       "      <td>-0.015098</td>\n",
       "      <td>0.055837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.002011e+09</td>\n",
       "      <td>4.168241e+09</td>\n",
       "      <td>-1.769392e+09</td>\n",
       "      <td>9.539553e+08</td>\n",
       "      <td>-3.003403e+09</td>\n",
       "      <td>2.583991e+09</td>\n",
       "      <td>-1.937712e+09</td>\n",
       "      <td>-4.011079e+09</td>\n",
       "      <td>-1.151520e+07</td>\n",
       "      <td>-7.186522e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.115475e+07</td>\n",
       "      <td>-8.677484e+05</td>\n",
       "      <td>-1.694474e+05</td>\n",
       "      <td>-0.091082</td>\n",
       "      <td>-0.308277</td>\n",
       "      <td>0.126776</td>\n",
       "      <td>0.032384</td>\n",
       "      <td>0.124902</td>\n",
       "      <td>0.021414</td>\n",
       "      <td>-0.095183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.895548e+09</td>\n",
       "      <td>-2.092054e+09</td>\n",
       "      <td>-1.279104e+09</td>\n",
       "      <td>-5.940138e+08</td>\n",
       "      <td>9.752376e+08</td>\n",
       "      <td>-2.481735e+09</td>\n",
       "      <td>-6.981636e+08</td>\n",
       "      <td>-3.100633e+08</td>\n",
       "      <td>-9.929031e+07</td>\n",
       "      <td>-3.954471e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.818691e+07</td>\n",
       "      <td>-1.373497e+06</td>\n",
       "      <td>-1.614229e+06</td>\n",
       "      <td>-0.168585</td>\n",
       "      <td>-0.031901</td>\n",
       "      <td>-0.240894</td>\n",
       "      <td>-0.036218</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>-0.071079</td>\n",
       "      <td>0.135636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1             2             3             4   \\\n",
       "0 -2.523242e+09 -1.918231e+09 -1.232079e+09 -1.776376e+09 -2.241226e+09   \n",
       "1 -3.190167e+09 -2.229378e+09 -1.542280e+09 -1.132694e+09 -3.550784e+09   \n",
       "2  3.923038e+08 -1.977646e+09  2.672523e+09 -3.915985e+09  1.047293e+09   \n",
       "3  2.002011e+09  4.168241e+09 -1.769392e+09  9.539553e+08 -3.003403e+09   \n",
       "4 -1.895548e+09 -2.092054e+09 -1.279104e+09 -5.940138e+08  9.752376e+08   \n",
       "\n",
       "             5             6             7             8             9   ...  \\\n",
       "0 -2.137455e+09 -1.284218e+09 -4.522613e+08 -1.019373e+08 -5.526863e+07  ...   \n",
       "1 -9.206884e+08  4.735889e+09 -7.588887e+08 -1.324696e+08 -8.904601e+06  ...   \n",
       "2 -3.084126e+09 -3.835881e+08 -1.973793e+08 -7.613600e+07 -3.861154e+07  ...   \n",
       "3  2.583991e+09 -1.937712e+09 -4.011079e+09 -1.151520e+07 -7.186522e+07  ...   \n",
       "4 -2.481735e+09 -6.981636e+08 -3.100633e+08 -9.929031e+07 -3.954471e+07  ...   \n",
       "\n",
       "             20            21            22        23        24        25  \\\n",
       "0  5.990670e+08 -9.863251e+05 -1.488518e+06  0.021262 -0.388106  0.039451   \n",
       "1 -5.230878e+06 -1.021334e+06 -1.433085e+06 -0.309381 -0.336137 -0.021758   \n",
       "2 -1.456694e+07 -4.647027e+05 -1.496466e+06 -0.373196  0.290911 -0.039027   \n",
       "3 -1.115475e+07 -8.677484e+05 -1.694474e+05 -0.091082 -0.308277  0.126776   \n",
       "4 -1.818691e+07 -1.373497e+06 -1.614229e+06 -0.168585 -0.031901 -0.240894   \n",
       "\n",
       "         26        27        28        29  \n",
       "0 -0.105008 -0.000646  0.046449  0.058511  \n",
       "1 -0.073707 -0.018794 -0.031770  0.026735  \n",
       "2  0.134702  0.152492 -0.015098  0.055837  \n",
       "3  0.032384  0.124902  0.021414 -0.095183  \n",
       "4 -0.036218  0.024268 -0.071079  0.135636  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform using our PCA model\n",
    "pca.fit(X_train)\n",
    "X_red = pca.transform(X_train)\n",
    "pd.DataFrame(X_red).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might've noticed that most machine learning with scikit learn involves:\n",
    "- Instantiating a transformer or model.\n",
    "- Fitting this to our data using `.fit()`.\n",
    "- Transforming or predicting using `.transform()` or `.predict()`.\n",
    "\n",
    "This simple, general process is one of scikit learn's greatest features, and it means that we can simplify our ML process using **Pipelines**. A Pipeline allows you to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KNN, SVM, and Logistic Regression models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these into three Pipelines, one for each model\n",
    "knn_pipe = Pipeline([('Scaler', StandardScaler()), \n",
    "                     ('PCA', PCA()), \n",
    "                     ('Model', KNeighborsClassifier())])\n",
    "\n",
    "svm_pipe = Pipeline([('Scaler', StandardScaler()), \n",
    "                     ('PCA', PCA()), \n",
    "                     ('Model', SVC())])\n",
    "\n",
    "log_reg_pipe = Pipeline([('Scaler', StandardScaler()), \n",
    "                         ('PCA', PCA()), \n",
    "                         ('Model', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_score = 100*cross_val_score(knn_pipe, X_train, y_train).mean()\n",
    "svm_score = 100*cross_val_score(svm_pipe, X_train, y_train).mean()\n",
    "log_reg_score = 100*cross_val_score(log_reg_pipe, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score:\n",
      "96.66877407883038\n"
     ]
    }
   ],
   "source": [
    "print('KNN Accuracy Score:')\n",
    "print(knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score:\n",
      "96.77348612071522\n"
     ]
    }
   ],
   "source": [
    "print('SVM Accuracy Score:')\n",
    "print(svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score:\n",
      "96.62686730986643\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy Score:')\n",
    "print(log_reg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortfallings of accuracy:\n",
    ">**Example:**\n",
    "> Imagine if I told you I can build a machine learning model that predicts whether or not an applicant is admitted into Harvard with 96.4% accuracy. Sounds good right! Now what if I told you the model works by predicting `NOT_ACCEPTED` to every applicant, irrespective of any data. This works as Harvard has a 4.6% admissions rate, but is our model any good?  \n",
    "\n",
    "Most often we care "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation sample\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Confusion Matrix:\n",
      "[[734   6]\n",
      " [ 22   2]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred = knn_pipe.predict(X_val)\n",
    "print('KNN Confusion Matrix:')\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Confusion Matrix:\n",
      "[[740   0]\n",
      " [ 24   0]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "svm_pipe.fit(X_train, y_train)\n",
    "y_pred = svm_pipe.predict(X_val)\n",
    "print('SVM Confusion Matrix:')\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix:\n",
      "[[737   3]\n",
      " [ 18   6]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "log_reg_pipe.fit(X_train, y_train)\n",
    "y_pred = log_reg_pipe.predict(X_val)\n",
    "print('Logistic Regression Confusion Matrix:')\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing confusion matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       920\n",
      "           1       0.38      0.09      0.14        35\n",
      "\n",
      "    accuracy                           0.96       955\n",
      "   macro avg       0.67      0.54      0.56       955\n",
      "weighted avg       0.94      0.96      0.95       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred = knn_pipe.predict(X_val)\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       920\n",
      "           1       1.00      0.03      0.06        35\n",
      "\n",
      "    accuracy                           0.96       955\n",
      "   macro avg       0.98      0.51      0.52       955\n",
      "weighted avg       0.97      0.96      0.95       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "svm_pipe.fit(X_train, y_train)\n",
    "y_pred = svm_pipe.predict(X_val)\n",
    "print('SVM Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       920\n",
      "           1       0.36      0.14      0.20        35\n",
      "\n",
      "    accuracy                           0.96       955\n",
      "   macro avg       0.66      0.57      0.59       955\n",
      "weighted avg       0.95      0.96      0.95       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict Logistic Regression pipeline\n",
    "log_reg_pipe.fit(X_train, y_train)\n",
    "y_pred = log_reg_pipe.predict(X_val)\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance and Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrate class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6fd88098f7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bankrupt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6)) \n",
    "ax.bar([0,1],y_train.value_counts())\n",
    "ax.set_xlabel('Bankrupt')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_title('Distribution of company bankruptcy ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b01407c37f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c955d8ddcf0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After OverSampling: X_train shape: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After OverSampling: y_train shape: {} \\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After OverSampling, counts of label '1': {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_res\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_res' is not defined"
     ]
    }
   ],
   "source": [
    "print('After OverSampling: X_train shape: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling: y_train shape: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       920\n",
      "           1       0.38      0.09      0.14        35\n",
      "\n",
      "    accuracy                           0.96       955\n",
      "   macro avg       0.67      0.54      0.56       955\n",
      "weighted avg       0.94      0.96      0.95       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "knn_pipe.fit(X_train_res, y_train_res)\n",
    "y_pred = knn_pipe.predict(X_val)\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       920\n",
      "           1       1.00      0.03      0.06        35\n",
      "\n",
      "    accuracy                           0.96       955\n",
      "   macro avg       0.98      0.51      0.52       955\n",
      "weighted avg       0.97      0.96      0.95       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "svm_pipe.fit(X_train_res, y_train_res)\n",
    "y_pred = svm_pipe.predict(X_val)\n",
    "print('SVM Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       920\n",
      "           1       0.36      0.14      0.20        35\n",
      "\n",
      "    accuracy                           0.96       955\n",
      "   macro avg       0.66      0.57      0.59       955\n",
      "weighted avg       0.95      0.96      0.95       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict Logistic Regression pipeline\n",
    "log_reg_pipe.fit(X_train_res, y_train_res)\n",
    "y_pred = log_reg_pipe.predict(X_val)\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression: \n",
    "Data set: \n",
    "- Pipelines\n",
    "- Regularization\n",
    "- Linear, ridge & SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning: \n",
    "Data set:\n",
    "- Pipelines\n",
    "- PCA\n",
    "- Regularization\n",
    "- Linear, ridge & SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets start by reading in our data set into a pandas DataFrame and getting some info on its dimensions and composition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that our data has "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
