{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3069d7ec",
   "metadata": {},
   "source": [
    "# Python for Data Science Practice Session 5 : Mathematics and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7523e7f",
   "metadata": {},
   "source": [
    "In this session, we will through two classification problems. We will be learning how to use Logistic Regression in the first mini-project, and a Feed Forward Neural Network in the second one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc99fb8",
   "metadata": {},
   "source": [
    "## NBA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb226f8d",
   "metadata": {},
   "source": [
    "Our dataset for this mini-project is about NBA players. It contains the performance metrics of each NBA player, and those metrics will be used to predict whether the basketball player's career will last for more than 5 years or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bb4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Pandas, Numpy, Matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741c7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e13163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the first 5 rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5801e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset's info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e04f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many missing values do we have?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e7d0c",
   "metadata": {},
   "source": [
    "Using what you learned from the fourth session, impute the missing data in this dataset with whichever imputation method you think is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0e0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862dea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View a summary of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d50a89",
   "metadata": {},
   "source": [
    "Now, to get the dataset ready to be input into a classification model, drop the column `Name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b8447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the columnn Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf091a",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7018e3f",
   "metadata": {},
   "source": [
    "Logistic Regression is a traditional statistical modelling technique that is also used a lot in Machine Learning applications. If you have never seen it before, I would recommend you to watch StatQuest's video about Linear Regression from here (https://www.youtube.com/watch?v=yIYKR4sgzI8) to get the intuition behind it.\n",
    "\n",
    "StatQuest also has a series of three other videos that go through specifics such as the model's co-efficients and how they are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a947f6",
   "metadata": {},
   "source": [
    "-  - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb924e2f",
   "metadata": {},
   "source": [
    "Start by creating your `X` and `y` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6f5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b678405",
   "metadata": {},
   "source": [
    "Using `train_test_split` as taught in the teaching session, create `X_train`, `X_test`, `y_train` and `y_test` with `test_size` of 0.2, and `random_state` of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c0b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X_train, X_test, y_train and y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0041f",
   "metadata": {},
   "source": [
    "Now, we are going to standardize the data in X. The predictors in Logistic Regression have parameters associated with them that can be adjusted to take the different scales of the predictors into consideration, and so the difference in scales does not help in that matter. We standardize the data to help speed up the process of the convergence of the iterative algorithm that is used by Python to calculate those parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56caf0c3",
   "metadata": {},
   "source": [
    "We will be using `StandardScaler()` to do this as shown in the teaching session, but there is one thing I must add here that is different to how we used it in the clustering application. The scaling should be fitted <b>ONLY</b> on the training data, and not on both the training and test data. In a real life project, you only have access to your training data when you are creating your model, so you should think of your test data here as being unseen data. You should not touch it except when you have your model ready to be used on unseen data. Even when we assess the performance of our model, we will be using a subset of our training data called validation data to test our model on. Once we are pleased with the performance of our model, we can then apply it on our test data. This will all be clear in a bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33e3f5",
   "metadata": {},
   "source": [
    "For now, fit and transform the training data using `StandardScaler()` and then transform the test data using the same scaler. You can find the documentation for `StandardScaler()` here (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) if you're interested in learning more about its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee816b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6ec15",
   "metadata": {},
   "source": [
    "Now, import `LogisticRegression()` from `sklearn.linear_model`. You can find the documentation for `LogisticRegression()` here (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) if you're interested in learning more about its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39903cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875b0292",
   "metadata": {},
   "source": [
    "Now, we are going to create a Logistic Regression model and call it classifier. The only parameter I want you to specify is the `random_state` and I want you to set it to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c8cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a logistic regression model, call it classifier, and set random_state to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8560603",
   "metadata": {},
   "source": [
    "Now, we will start focussing on the performance of Logistic Regression on this dataset. This gets us back to the idea of validation data. The way we test the accuracy of the model is by using something called K-Fold Cross Validation. As explained in the teaching session, the training data gets split up into K folds. The model is then fitted to K-1 folds, and tested on the left-out fold. This process is then repeated on all of the combinations of K-1 folds, and all the left-out folds. The left out fold is what we call the validation data. From its name, the validation data is used to validate the performance and accuracy of our model. For each process, the accuracy of the model is calculated by testing its performance on the validation data. After finishing all of the processes, we will get the average value for the accuracies as an indicator on the general performance of the model.\n",
    "\n",
    "It might seem unintuitive to use validation data as a way to test the performance of our model, even though we have defined what our test data is. But think about this for a moment. In real life projects, the test data generally do not come with their response variables, so how will we assess the performance of our model? What will we compare our predictions to? This is where validation data comes in handy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1882f46",
   "metadata": {},
   "source": [
    "Now, import `cross_val_score` from `sklearn.model_selection`. You can find the documentation for `cross_val_score` here (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) if you're interested in learning more about its parameters.\n",
    "\n",
    "Use it to perform a 5-Fold Cross Validation, and output the average accuracy of the model on the 5 validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fb049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the cross validation score over 5 folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3a945",
   "metadata": {},
   "source": [
    "We get an accuracy of approximately 71%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de339db",
   "metadata": {},
   "source": [
    "Now, fit the model on all of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7739ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model on the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513785c3",
   "metadata": {},
   "source": [
    "### Test model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b057b87",
   "metadata": {},
   "source": [
    "Create a variable called `y_pred` that contains the predictions of the test data in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d066b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9273661",
   "metadata": {},
   "source": [
    "Output the accuracy of the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8acd4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is\n"
     ]
    }
   ],
   "source": [
    "#Output the accuracy of the model on the test data\n",
    "print('The accuracy is',  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d4fac",
   "metadata": {},
   "source": [
    "We get an accuracy of approximately 70% on the test data, which is not too far off from what we got as an average over the validation data. \n",
    "\n",
    "Is this the best we can do? Definitely there is room for improvement, but I will leave this for you to explore if you're interested in exploring other classification models, or maybe even doing a little bit of feature engineering to improve the performance of logistic regression on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9aaa20",
   "metadata": {},
   "source": [
    "## Is the accuracy metric enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44296623",
   "metadata": {},
   "source": [
    "Although accuracy is a good starting point to illustrate our model's predictive performance, it does come with some caveats. This is perhaps better illustrated by an example:\n",
    "\n",
    ">**Example:**\n",
    ">\n",
    "> *Imagine if I told you I can build a machine learning model that predicts whether or not an applicant is admitted into Harvard with 96.4% accuracy. Sounds good right! Now what if I told you the model works by predicting `NOT_ACCEPTED` to every applicant, irrespective of any data observed. This works as Harvard has a 4.6% admissions rate, but is our model any good?*  \n",
    "\n",
    "Often, we must consider using other metrics in classification. The best way to start out is by analysing how true positives/negatives are distributed among classes. We can do this through a confusion matrix, which represents this distribution in the following form:\n",
    "\n",
    "\n",
    "<img src='https://miro.medium.com/max/2102/1*fxiTNIgOyvAombPJx5KGeA.png' width=\"450\" height=\"400\">\n",
    "\n",
    "\n",
    "To output the confusion matrix of our predictions, we use the `confusion_matrix()` function from scikit learn (for documentation, see [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion#sklearn.metrics.confusion_matrix)). Try outputting the confussion matrix for the model applied to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8bbf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import confusion_matrix and create a confusion matrix using y_pred and y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d29009",
   "metadata": {},
   "source": [
    "As you can see, the model's false negatives are approximately double that of the false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a10f7b",
   "metadata": {},
   "source": [
    "In some cases, the effect of false negatives might outweigh the effects of false positives. Think for example of a model that is used to predict whether a person has cancer or not. Falsely predicting that someone has cancer is not ideal, but it is far less problematic than falsely predicting that someone does not have cancer. It could be fatal. This is why, accuracy on its own is not enough to measure the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebb7b2",
   "metadata": {},
   "source": [
    "There are other metrics for you to look into such as:\n",
    "- <b>Sensitivity</b> (Sometimes called as <b>Recall</b>)\n",
    "\n",
    "- <b>Specificity</b> \n",
    "\n",
    "- <b>PPV</b> (Sometimes called as <b>Precision</b>)\n",
    "\n",
    "- <b>NPV</b>\n",
    "\n",
    "- <b>F1 Score</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5237a4fe",
   "metadata": {},
   "source": [
    "## Can we improve the performance of our Logistic Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d741a4",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e92ad9",
   "metadata": {},
   "source": [
    "One thing that you might have noticed is that we have have a large dimensional dataset (19 columns), and we don't have enough data points (1340 rows). This could lead to overfitting. Think about it in this way. The more features we have, the more complex our model can be, and the more it can align itself to fit the training data more. This could lead to the model fitting to the noises as well, which is not what we want. We want a model that generalises well and captures the main structure and properties of the data; to perform well on unseen data. \n",
    "\n",
    "The problems arising from having high dimensional data is called the Curse of Dimensionality. You can read more about it here: https://en.wikipedia.org/wiki/Curse_of_dimensionality#Machine_Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1823218",
   "metadata": {},
   "source": [
    "One way to help with this is to reduce the dimensionality of our data. We are going to use a model called PCA to do this. Read more about it from here: https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c493ec",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce7424",
   "metadata": {},
   "source": [
    "Import `PCA` from `sklearn.decomposition`. You can find its documentation here (https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) if you'd like to read more about its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00cd2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca9335",
   "metadata": {},
   "source": [
    "Create a PCA model with `12` components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "610544a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a PCA model with 12 components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "838ff824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and transform X using the pca model, name it as X_reduced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fcbf03",
   "metadata": {},
   "source": [
    "Now using X_reduced, follow the exact same steps as before. To help remind you, here is a list of the steps that you should follow:\n",
    "\n",
    "1) Create training and test data using `train_test_split`\n",
    "\n",
    "2) Standardize the data\n",
    "\n",
    "3) Create the classifier\n",
    "\n",
    "4) Use 5-Fold Cross Validation to calculate the average accuracy of the model\n",
    "\n",
    "5) Fit the classifier on the whole training data\n",
    "\n",
    "6) Predict with the model on the test data\n",
    "\n",
    "7) Calculate the accuracy of the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b71fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68bba553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f02870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c9787c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62e62746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1244fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0272e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of the model on the test data\n",
    "print('The accuracy is',  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87708a8",
   "metadata": {},
   "source": [
    "The increase in the cross validation score is insignificant, but the increase in the accuracy on the test data is definitely very welcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a51113",
   "metadata": {},
   "source": [
    "- - - -- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0027257",
   "metadata": {},
   "source": [
    "## An introduction to Feed Forward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426f9b7",
   "metadata": {},
   "source": [
    "In this section, we are going to apply a very simple feed forward neural network on the popular MNIST dataset. The MNIST dataset contains 28x28 images of hand-written digits. We will be using the neural network to predict the digit that is drawn in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab6e2e",
   "metadata": {},
   "source": [
    "It would be useless to go through the tasks of this section without having at least a simple intuition into how a feed forward neural network works. I would highly recommend watching the 3Blue1Brown series about neural networks (or at least the first video), which you can access from here: https://www.youtube.com/watch?v=aircAruvnKk\n",
    "\n",
    "There are also loads of other resources online which you can check out to learn more about the specifics of neural networks, as well as other forms of neural networks such as Convolutional Neural Networks, Recurrent Neural Networks, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe3447",
   "metadata": {},
   "source": [
    "Now, we will be using a very popular library for Machine Learning called <b> TensorFlow</b>. TensorFlow is an open source free library on Python used across a range of tasks but has a particular focus on the training and inference of neural networks. To install it, type on your command line/terminal `pip install tensorflow`. Then, import it into this notebook as `tf`. Also, import `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ace7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tensorflow as tf and sklearn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556eb98",
   "metadata": {},
   "source": [
    "Now, we are going to retrieve the MNIST dataset from TensorFlow. Specifically, from a high-level API called Keras that is built on top of TensorFlow, with a focus on implementing deep learning models (i.e. Neural Networks with large numbers of hidden layers) with an intuitive approach. Use `tf.keras.datasets` to retrieve the MNIST dataset, and call it `mnist`. You can read more about this here (https://www.tensorflow.org/api_docs/python/tf/keras/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59aa6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the dataset from TensorFlow, and call it mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e88720",
   "metadata": {},
   "source": [
    "By typing `mnist.load_data()`, it outputs a 2x2 block matrix, where the first row of blocks contain the x_train matrix and y_train vector, and the second row of blocks contain the x_test matrix and the y_test vector. Use this info to create `x_train`, `y_train`, `x_test` and `y_test` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "025eaeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training and the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad372eb",
   "metadata": {},
   "source": [
    "Print the shape of `X_train`, `y_train`, `X_test` and `y_test` to have an overview of the number of images that we have in the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962e637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape is\n",
      "y_train's shape is\n",
      "X_test's shape is\n",
      "y_test's shape is\n"
     ]
    }
   ],
   "source": [
    "#Print the shape of x_train, y_train, x_test and y_test\n",
    "print( \"X_train's shape is\" , )\n",
    "print( \"y_train's shape is\" , )\n",
    "print( \"X_test's shape is\" , )\n",
    "print( \"y_test's shape is\" , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c11fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first data entry in x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4564dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first data entry in y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ec286",
   "metadata": {},
   "source": [
    "As you can see:\n",
    "- A data entry in X_train consists of a 28x28 matrix, where each entry in the matrix represents the pixel value at this position in the image. \n",
    "\n",
    "- A data entry in y_train consists of the digit that is drawn in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ff785",
   "metadata": {},
   "source": [
    "Now, plot the first three images from the training data:\n",
    "\n",
    "<b> Hint: </b> Look up `plt.imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f7ec99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the first three images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecac94b",
   "metadata": {},
   "source": [
    "Now that we have understood the structure of our data, let us start working on creating the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee00ce",
   "metadata": {},
   "source": [
    "-- - - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01544a2b",
   "metadata": {},
   "source": [
    "A first step that is commonly used for projects like this one is to normalise the input data. Similar to Logistic Regression, it helps in speeding up the process of learning for the neural network, and can help in saving memory as well.\n",
    "\n",
    "Use `tf.keras.utils.normalize` to do so. You can find its documentation here (https://www.tensorflow.org/api_docs/python/tf/keras/utils/normalize). Apply it to X_train, and set `axis` to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99bf9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply tf.keras.utils.normalize on x_train and set axis to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24646572",
   "metadata": {},
   "source": [
    "- - - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2333e2a",
   "metadata": {},
   "source": [
    "Now, we are going to create our model for the neural network. One thing that you will most probably hear would be that building a neural network is sort of a form of art. There are lots of properties for the neural network that have loads of different options available, and you, the artist, get to choose and match the ones that you think would work best for your specific case. For this project, I will tell you what options to choose, and explain them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea1b1a5",
   "metadata": {},
   "source": [
    "To start off, we will choose a model from Keras called Sequential. A Sequential model is a model which allows you to create layers in a step by step fashion, which is what we want in our Feed Forward Neural Network.\n",
    "\n",
    "You can find its documentation here (https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). Create a sequential model using the code `tf.keras.models.Sequential()`, and name it `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "159b6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sequential model using the code `tf.keras.models.Sequential()`, and name it `model`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341bf295",
   "metadata": {},
   "source": [
    "Next, we are going to create the layers for our neural network. In our case, we are going to have 1 input layer, two hidden layers and an output layer. \n",
    "\n",
    "Starting from the input layer, we would like to flatten the input layer as it was explained in the 3Blue1Brown video, so that we have one layer of 784 (28 x 28) nodes to accompany the pixels that we have. \n",
    "\n",
    "Use `model.add(tf.keras.layers.Flatten())`. You can find its documentation here (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "738f3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the input layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947d5cbc",
   "metadata": {},
   "source": [
    "Next, we are going to create the two hidden layers. We are going to let them have 128 nodes, with an activation function called ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c78614",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fdb2eb",
   "metadata": {},
   "source": [
    "ReLU - Rectified Linear Unit - is one of the most popular activation functions that are used for Neural Networks. It is defined as: \n",
    "\n",
    "$$ f(x) = max(x,0) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ed142",
   "metadata": {},
   "source": [
    "Plot the function in order to get an idea of what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fe93ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the ReLU function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b54f0b",
   "metadata": {},
   "source": [
    "Here is a link where you can read more about activation functions such as sigmoid and tanh, their drawbacks, and how ReLU outperforms them in some scenarios: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897398a5",
   "metadata": {},
   "source": [
    "Now, add the two hidden layers using the code `model.add(tf.keras.layers.Dense( -- arguments to be specified by you -- ))`, You can find its documentation here (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense).\n",
    "\n",
    "Set the number of nodes to `128` and the activation function to `tf.nn.relu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4868a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the two hidden layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727085ec",
   "metadata": {},
   "source": [
    "Now, we are going to add the output layer. As we have 10 classes, where each class represents a specific digit, we are going to set the nodes to `10`. As for the activation function, we are going to be using a function called softmax, which is called `tf.nn.softmax` in TensorFlow. In a nutshell, what softmax does is similar to what a logistic/sigmoid function does in logistic regression. It outputs a probability distribution taking values in the 10 different classes we have, so that each class has a probability associated with it, and the sum of the probabilities across the classes equal 1. \n",
    "\n",
    "Use `model.add(tf.keras.layers.Dense( -- arguments to be specified by you -- ))` again, set the nodes to `10` and the activation function to `tf.nn.softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32942caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the output layer with 10 nodes and softmax activation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea46ed",
   "metadata": {},
   "source": [
    "Now that we have created our layers, all we need to do now is to specifiy an optimizer for the neural network, a loss function and the metrics we would like to keep track of. \n",
    "\n",
    "- - - - - \n",
    "\n",
    "<b>Loss function:</b> This is a map\n",
    "\n",
    "$$ L : Y \\times Y \\to \\mathbb{R} $$\n",
    "\n",
    "which takes in the predicted value for y, the true value for y, and outputs a real number. It is created in a way in which it penalises inaccuracy and incorrectness. This means that, the farther away the predicted value is from the true value (in the continuous case), or when the predicted value is not equal to the true value (in the discrete case), the output of the loss function is larger.\n",
    "\n",
    "An example in the continuous case would be the mean squared error:\n",
    "\n",
    "$$ L(Y^*, Y) = (Y^* - Y)^2 $$\n",
    "\n",
    "An example in the discrete case is the zero-one loss:\n",
    "\n",
    "$$ L(Y^*, Y) = \\mathbb{1} \\{Y^* \\neq Y\\} $$\n",
    "\n",
    "When calculating the loss over the training data, you apply the loss function over every training point, sum over all of  the them and then average them.\n",
    "\n",
    "Intuitively, we are aiming for having more accurate predictions, which corresponds to having smaller loss function over the training data. One very important thing to mention is that using the parameters that minimise the loss function is not always ideal. Similar to what we had with Logistic Regression, It could lead to the model fitting to the training data extremely well, to the point that it learns the random noises of the training data and hence leads to overfitting and poor performance over unseen data. The main goal is to find parameters that learn the main structure and properties of the data to generalise and perform well over unseen data (the test data). \n",
    "\n",
    "This leads on well to what an optimizer is.\n",
    "\n",
    "<b>Optimizer:</b> An optimizer is an algorithm that is used to adjust the parameters of the model in a way that leads to the decreasing of the loss function value over the training data. An example for this would be gradient descent, which you should have seen in the 3Blue1Brown videos. \n",
    "\n",
    "- - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd50e6",
   "metadata": {},
   "source": [
    "Now, we are going to use an optimizer called <b> Adam (Adaptive Moment Estimation) </b>, which combines two stochastic gradient descent called <b> Adaptive Gradients </b> and <b> Root Mean Square Error </b>. Feel free to read more about them and find why this specific optimization algorithm is preferred to many other ones, but it's not essential to know how it works for now.\n",
    "\n",
    "As for the loss function, we will be using <b> Sparse Categorical Cross Entropy</b>. To explain what that is, we should start by explaining <b>Categorical Cross Entropy</b>. \n",
    "\n",
    "Recall how the output layer contained $10$ nodes representing the probability distribution of the $10$ classes. We would like a loss function that would be able to measure in some way how close or far away two probability distributions are from each other. This is exactly what Categorical Cross Entropy does.\n",
    "\n",
    "<b>Categorical Cross Entropy:</b> This is a loss function that compares the probability distributions of the true value and the predicted value. Let $K$ be the number of classes, and consider the training data given as pairs $(x,y)$, where $x$ is the vector of the predictor variables and $y$ is the response. $y \\in \\mathbb{R}^k $ is a vector containing the probabilities of the classes for the true value, where $y_j = 1 $ if $x$ belongs to class $j$, and $0$ otherwise. Let $y^*$ be the vector containing the predicted probabilities of the classes, We then have:\n",
    "\n",
    "$$ L(y,y^*) = -\\sum_{i=0}^{K} y_i log (y_i^*) + (1-y_i)log(1-y_i^*)  $$\n",
    "\n",
    "For example, assume we have an image with a digit $5$ drawn in it. This means that $y$, the probability distribution for the true value, is equal to $(0,0,0,0,0,1,0,0,0,0)$. $y^*$ would be represented by a vector containing the values in the nodes in the output layer of our neural network, with each entry (or node in the layer) representing the probability of the image having a specific digit. $K$ would be equal to $10$. This means that the categorical cross entropy would be:\n",
    "\n",
    "$$ L(y,y^*) = -\\sum_{i=0}^{10} y_i log (y_i^*) + (1-y_i)log(1-y_i^*) $$\n",
    "\n",
    "So, the closer $y_5^*$ is to $1$, the higher the probability that the image has the digit $5$ drawn in it, the smaller the loss function.\n",
    "\n",
    "The one we are going to use is called <b> Sparse Categorical Cross Entropy</b>, which differs from the normal categorical cross entropy in the fact that we have $y$ taking values in $0,1,2,3, ... , 9$ instead of one-hot encoded vectors in $\\mathbb{R}^k$ like the examples shown above.\n",
    "\n",
    "-------\n",
    "\n",
    "Now, use `mode.compile( -- arguments to be specified by you --  ) `, which you can find its documentation here (https://www.tutorialspoint.com/keras/keras_model_compilation.htm). \n",
    "\n",
    "Set the `optimizer` argument as `adam`, the `loss` argument as `sparse_categorical_crossentropy` and the `metrics` as `['accuracy']`\n",
    "\n",
    "-------\n",
    "\n",
    "Now, use `mode.compile( -- arguments to be specified by you --  ) `, which you can find its documentation here (https://www.tutorialspoint.com/keras/keras_model_compilation.htm). \n",
    "\n",
    "Set the `optimizer` argument as `adam`, the `loss` argument as `sparse_categorical_crossentropy` and the `metrics` as `['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca35b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use model.compile with the prescribed arguments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409a68f",
   "metadata": {},
   "source": [
    "Now, we are going to apply 5-Fold Cross Validation to assess the average accuracy of the model. This is a bit different to when we used `cross_val_score` from before, so you will find below a written function that takes as arguments the predictor and response variables for the training data, as well as the number of folds. (Definitely feel free to ignore my function and create your own one!) It will then output two lists called `scores` (containing the accuracy of the model over the 5 validation datasets) and `histories` containing information about the model fit on the different folds such as the value for the loss function over the training data and the validation loss of the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a637b60",
   "metadata": {},
   "source": [
    "One thing that is new in my code is `epochs`. An epoch is the process of going through a step of forward propogation and back propogation to update the weights of the model. Setting `epochs=3` in the fitting function mean that we do this process 3 times over all of the data. One thing that you can explore is, at what value of epochs does the model start to overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "3702db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "dbd1aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds):\n",
    "    scores, histories = list(), list()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state = 0)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        #define_model\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "        model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "        model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "        model.compile(optimizer = 'adam',\n",
    "             loss= 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "        # fit model\n",
    "        history = model.fit(trainX, trainY, epochs=3, validation_data=(testX, testY))\n",
    "        # evaluate model\n",
    "        acc = model.evaluate(testX, testY)[1]\n",
    "        # stores scores\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20043de",
   "metadata": {},
   "source": [
    "Now, run the function on `x_train` and `y_train`, setting the number of folds to `5`, and save the output in a variable called `results`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "065d0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the evaluate_model function\n",
    "results = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94fb5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e4f3c2",
   "metadata": {},
   "source": [
    "Print the average accuracy over the different validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a9a8ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy over the different validation sets is\n"
     ]
    }
   ],
   "source": [
    "#Print the average accuracy over the different validation sets\n",
    "print('The average accuracy over the different validation sets is', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3a49f",
   "metadata": {},
   "source": [
    "Here is another function that provides visualisations of the cross entropy loss values and the accuracy for the training data and the validation data that we got over the 3 epochs in the 5-Fold Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "a5cd4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        fig, ax = plt.subplots(1,2)\n",
    "        ax[0].set_title('Cross Entropy Loss')\n",
    "        ax[0].plot(histories[i].history['loss'], color='blue', label='train', marker='.') \n",
    "        ax[0].plot(histories[i].history['val_loss'], color='orange', label='test', marker='.')\n",
    "        ax[0].legend()\n",
    "        # plot accuracy\n",
    "        ax[1].set_title('Classification Accuracy')\n",
    "        ax[1].plot(histories[i].history['accuracy'], color='blue', label='train', marker='.')\n",
    "        ax[1].plot(histories[i].history['val_accuracy'], color='orange', label='test', marker='.')\n",
    "        ax[1].legend()\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0755afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use summarize_diagnostics on histories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c624bc",
   "metadata": {},
   "source": [
    "Try to interpret those visualisations on your own. You can also plot them all on top of each other to get a general overview of how the cross entropy loss and accuracy change. You can use both the functions `evaluate_model` and `summarize_diagnostics` and try to experiment with different epochs values, different folds and how this might affect the values for the accuracy and the cross entropy loss on the training and validating data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0758424",
   "metadata": {},
   "source": [
    "Now, fit the model on all of the training data, and output the accuracy on the test data by setting the `validation_data` parameter in the `model.fit()` function as y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d072f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac828ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test data is\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy on the test data is', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df159e9",
   "metadata": {},
   "source": [
    "Nowadays, Feed Forward Neural Networks aren't the most powerful when it comes to image classification. Convolutional Neural Networks have become the standard for image classification due to the improvements they have in performance over the other neural networks. If you're interested, check out how a CNN works, and you can then have a look at this tutorial: https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d \n",
    "to understand how you can apply CNN on the MNIST dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
